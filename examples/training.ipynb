{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (IV) Model Building\n",
    "You can also train the neural network on your data and build and test your own model using the following modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build your own EQTransformer with varying encoder sizes and train it using your own data. Your data should be in the same format as our sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 18:29:41.137673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-25 18:29:41.137729: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/human/git/EQTransformer/EQTransformer/core/trainer.py:274: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  training, validation=_split(args, save_dir)\n",
      "2023-10-25 18:29:48.397307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-25 18:29:48.397364: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-25 18:29:48.397398: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hpspectrex360): /proc/driver/nvidia/version does not exist\n",
      "2023-10-25 18:29:48.397863: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 6000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 6000, 8)      96          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3000, 8)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 3000, 16)     1168        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1500, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1500, 16)     1808        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 750, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 750, 32)      3616        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 375, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 375, 32)      5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 188, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 188, 64)      10304       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 94, 64)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 94, 64)       12352       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 47, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 47, 64)       256         max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 47, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 47, 64)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 64)       256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 47, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 47, 64)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 47, 64)       256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 47, 64)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 47, 64)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 47, 64)       256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 47, 64)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 47, 64)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 47, 64)       12352       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 64)       0           add[0][0]                        \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 47, 32)       10368       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 47, 16)       528         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 47, 16)       64          conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentionD0 (SeqSelfAttention)  [(None, 47, 16), (No 1089        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 47, 16)       0           batch_normalization_4[0][0]      \n",
      "                                                                 attentionD0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 47, 16)       32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward (FeedForward)      (None, 47, 16)       4240        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 47, 16)       0           layer_normalization[0][0]        \n",
      "                                                                 feed_forward[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 47, 16)       32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attentionD (SeqSelfAttention)   [(None, 47, 16), (No 1089        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 47, 16)       0           layer_normalization_1[0][0]      \n",
      "                                                                 attentionD[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 47, 16)       32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward_1 (FeedForward)    (None, 47, 16)       4240        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 47, 16)       0           layer_normalization_2[0][0]      \n",
      "                                                                 feed_forward_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 47, 16)       32          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attentionP (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attentionS (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 94, 16)       0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1D)  (None, 94, 16)       0           attentionP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling1D) (None, 94, 16)       0           attentionS[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 94, 64)       3136        up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 94, 64)       3136        up_sampling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 94, 64)       3136        up_sampling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 188, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, 188, 64)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling1D) (None, 188, 64)      0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 376, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1D)  (None, 376, 64)      0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling1D) (None, 376, 64)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 752, 32)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling1D) (None, 752, 32)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling1D) (None, 752, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d (Cropping1D)         (None, 750, 32)      0           up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 750, 32)      7200        cropping1d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 750, 32)      7200        cropping1d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 750, 32)      7200        cropping1d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1D)  (None, 1500, 32)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_11 (UpSampling1D) (None, 1500, 32)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_18 (UpSampling1D) (None, 1500, 32)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, 3000, 16)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_12 (UpSampling1D) (None, 3000, 16)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_19 (UpSampling1D) (None, 3000, 16)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1D)  (None, 6000, 16)     0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_13 (UpSampling1D) (None, 6000, 16)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling1D) (None, 6000, 16)     0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detector (Conv1D)               (None, 6000, 1)      89          conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_P (Conv1D)               (None, 6000, 1)      89          conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_S (Conv1D)               (None, 6000, 1)      89          conv1d_32[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 258,807\n",
      "Trainable params: 258,263\n",
      "Non-trainable params: 544\n",
      "__________________________________________________________________________________________________\n",
      "Started training in generator mode ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/anaconda3/envs/eqt/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2023-10-25 18:29:52.828412: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-10-25 18:29:52.844823: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000800000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Learning rate:  0.001\n",
      "4/4 [==============================] - 276s 4s/step - loss: 0.6285 - detector_loss: 0.4848 - picker_P_loss: 0.5599 - picker_S_loss: 0.6898 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 8.5709e-04 - val_loss: 0.4318 - val_detector_loss: 0.7541 - val_picker_P_loss: 0.1363 - val_picker_S_loss: 0.6155 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43183, saving model to /home/human/git/EQTransformer/examples/test_trainer_outputs/models/test_trainer_001.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/anaconda3/envs/eqt/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Learning rate:  0.001\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3387 - detector_loss: 0.3862 - picker_P_loss: 0.1043 - picker_S_loss: 0.5029 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.1788 - val_detector_loss: 0.4651 - val_picker_P_loss: 0.0453 - val_picker_S_loss: 0.2478 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43183 to 0.17885, saving model to /home/human/git/EQTransformer/examples/test_trainer_outputs/models/test_trainer_002.h5\n",
      "Epoch 3/10\n",
      "Learning rate:  0.001\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1068 - detector_loss: 0.3060 - picker_P_loss: 0.0741 - picker_S_loss: 0.1103 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0727 - val_detector_loss: 0.4416 - val_picker_P_loss: 0.0770 - val_picker_S_loss: 0.0337 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17885 to 0.07270, saving model to /home/human/git/EQTransformer/examples/test_trainer_outputs/models/test_trainer_003.h5\n",
      "Epoch 4/10\n",
      "Learning rate:  0.001\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0925 - detector_loss: 0.3409 - picker_P_loss: 0.1046 - picker_S_loss: 0.0587 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0859 - val_detector_loss: 0.4193 - val_picker_P_loss: 0.0617 - val_picker_S_loss: 0.0707 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07270\n",
      "Epoch 5/10\n",
      "Learning rate:  0.001\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1027 - detector_loss: 0.3460 - picker_P_loss: 0.0717 - picker_S_loss: 0.1007 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0750 - val_detector_loss: 0.3689 - val_picker_P_loss: 0.0336 - val_picker_S_loss: 0.0759 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07270\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/human/git/EQTransformer/EQTransformer/core')\n",
    "\n",
    "from trainer import trainer\n",
    "# trainer(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "        # input_csv='../ModelsAndSampleData/100samples.csv',\n",
    "trainer(input_hdf5='/home/human/Downloads/chunk2.hdf5',\n",
    "        input_csv='/home/human/Downloads/chunk2.csv',\n",
    "        output_name='test_trainer',\n",
    "        input_dimention=(6000,1),\n",
    "        cnn_blocks=2,\n",
    "        lstm_blocks=1,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        drop_rate=0.2,\n",
    "        label_type='gaussian',\n",
    "        add_event_r=0.6,\n",
    "        add_gap_r=0.2,\n",
    "        shift_event_r=0.9,\n",
    "        add_noise_r=0.5,\n",
    "        mode='generator',\n",
    "        train_valid_test_split=[0.0001, 0.00005, 0.20],\n",
    "        batch_size=20,\n",
    "        epochs=1,\n",
    "        patience=2,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Test Your Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then test the model you just trained based on the ground truth labels:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "Loading is complete!\n",
      "Testing ...\n",
      "Writting results into: \" test_tester_outputs \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:33<00:00, 16.68s/it]"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.tester import tester\n",
    "tester(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "       input_testset='test_trainer_outputs/test.npy',\n",
    "       input_model='test_trainer_outputs/models/test_trainer_001.h5',\n",
    "       output_name='test_tester',\n",
    "       detection_threshold=0.20,\n",
    "       P_threshold=0.1,\n",
    "       S_threshold=0.1,\n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True,\n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=10,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
